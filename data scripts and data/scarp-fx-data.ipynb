{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbb415a8",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-07-01T18:49:14.958041Z",
     "iopub.status.busy": "2022-07-01T18:49:14.957509Z",
     "iopub.status.idle": "2022-07-01T18:49:14.973033Z",
     "shell.execute_reply": "2022-07-01T18:49:14.972140Z"
    },
    "papermill": {
     "duration": 0.024062,
     "end_time": "2022-07-01T18:49:14.975600",
     "exception": false,
     "start_time": "2022-07-01T18:49:14.951538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2a93766",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-01T18:49:14.984336Z",
     "iopub.status.busy": "2022-07-01T18:49:14.983574Z",
     "iopub.status.idle": "2022-07-01T18:51:21.940365Z",
     "shell.execute_reply": "2022-07-01T18:51:21.938922Z"
    },
    "papermill": {
     "duration": 126.96465,
     "end_time": "2022-07-01T18:51:21.943405",
     "exception": false,
     "start_time": "2022-07-01T18:49:14.978755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USDJPY shape :  (7415787, 6)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "class TimeFrame:\n",
    "    ONE_MINUTE = 'M1'\n",
    "    TICK_DATA = 'T'\n",
    "    TICK_DATA_LAST = 'T_LAST'\n",
    "    TICK_DATA_BID = 'T_BID'\n",
    "    TICK_DATA_ASK = 'T_ASK'\n",
    "\n",
    "\n",
    "class Platform:\n",
    "    META_TRADER = 'MT'\n",
    "    GENERIC_ASCII = 'ASCII'\n",
    "    EXCEL = 'XLSX'\n",
    "    NINJA_TRADER = 'NT'\n",
    "    META_STOCK = 'MS'\n",
    "\n",
    "\n",
    "class URL:\n",
    "    META_TRADER = 'https://www.histdata.com/download-free-forex-historical-data/?/metatrader/1-minute-bar-quotes/'\n",
    "    ASCII_1M = 'https://www.histdata.com/download-free-forex-historical-data/?/ascii/1-minute-bar-quotes/'\n",
    "    ASCII_TICK_DATA = 'https://www.histdata.com/download-free-forex-historical-data/?/ascii/tick-data-quotes/'\n",
    "    EXCEL = 'https://www.histdata.com/download-free-forex-historical-data/?/excel/1-minute-bar-quotes/'\n",
    "    NINJA_TRADER = 'https://www.histdata.com/download-free-forex-historical-data/?/ninjatrader/1-minute-bar-quotes/'\n",
    "    NINJA_TRADER_LAST_QUOTES = 'https://www.histdata.com/download-free-forex-historical-data/?/ninjatrader/tick-last-quotes/'\n",
    "    NINJA_TRADER_BID_QUOTES = 'https://www.histdata.com/download-free-forex-historical-data/?/ninjatrader/tick-bid-quotes/'\n",
    "    NINJA_TRADER_ASK_QUOTES = 'https://www.histdata.com/download-free-forex-historical-data/?/ninjatrader/tick-ask-quotes/'\n",
    "    META_STOCK = 'https://www.histdata.com/download-free-forex-historical-data/?/metastock/1-minute-bar-quotes/'\n",
    "\n",
    "\n",
    "def get_prefix_referer(time_frame, platform):\n",
    "    if time_frame == TimeFrame.TICK_DATA and platform == Platform.GENERIC_ASCII:\n",
    "        return URL.ASCII_TICK_DATA\n",
    "    elif time_frame == TimeFrame.TICK_DATA_LAST and platform == Platform.NINJA_TRADER:\n",
    "        return URL.NINJA_TRADER_LAST_QUOTES\n",
    "    elif time_frame == TimeFrame.TICK_DATA_BID and platform == Platform.NINJA_TRADER:\n",
    "        return URL.NINJA_TRADER_BID_QUOTES\n",
    "    elif time_frame == TimeFrame.TICK_DATA_ASK and platform == Platform.NINJA_TRADER:\n",
    "        return URL.NINJA_TRADER_ASK_QUOTES\n",
    "    elif time_frame == TimeFrame.ONE_MINUTE and platform == Platform.GENERIC_ASCII:\n",
    "        return URL.ASCII_1M\n",
    "    elif time_frame == TimeFrame.ONE_MINUTE and platform == Platform.META_TRADER:\n",
    "        return URL.META_TRADER\n",
    "    elif time_frame == TimeFrame.ONE_MINUTE and platform == Platform.EXCEL:\n",
    "        return URL.EXCEL\n",
    "    elif time_frame == TimeFrame.ONE_MINUTE and platform == Platform.NINJA_TRADER:\n",
    "        return URL.NINJA_TRADER\n",
    "    elif time_frame == TimeFrame.ONE_MINUTE and platform == Platform.META_STOCK:\n",
    "        return URL.META_STOCK\n",
    "    else:\n",
    "        raise Exception('Invalid combination of time_frame and platform.')\n",
    "\n",
    "\n",
    "def get_referer(referer_prefix, pair, year, month):\n",
    "    if month is not None:\n",
    "        return referer_prefix + '{}/{}/{}'.format(pair.lower(), year, month)\n",
    "    return referer_prefix + '{}/{}'.format(pair.lower(), year)\n",
    "\n",
    "\n",
    "def download_hist_data(year='2016',\n",
    "                       month=None,\n",
    "                       pair='eurusd',\n",
    "                       time_frame=TimeFrame.ONE_MINUTE,\n",
    "                       platform=Platform.GENERIC_ASCII,\n",
    "                       output_directory='.',\n",
    "                       verbose=True):\n",
    "\n",
    "    tick_data = time_frame.startswith('T')\n",
    "    if (not tick_data) and ((int(year) >= datetime.now().year and month is None) or\n",
    "                            (int(year) <= datetime.now().year - 1 and month is not None)):\n",
    "        msg = 'For the current year, please specify month=7 for example.\\n'\n",
    "        msg += 'For the past years, please query per year with month=None.'\n",
    "        raise AssertionError(msg)\n",
    "\n",
    "    prefix_referer = get_prefix_referer(time_frame, platform)\n",
    "    referer = get_referer(prefix_referer, pair.lower(), year, month)\n",
    "\n",
    "    # Referer is the most important thing here.\n",
    "    headers = {'Host': 'www.histdata.com',\n",
    "               'Connection': 'keep-alive',\n",
    "               'Content-Length': '104',\n",
    "               'Cache-Control': 'max-age=0',\n",
    "               'Origin': 'https://www.histdata.com',\n",
    "               'Upgrade-Insecure-Requests': '1',\n",
    "               'Content-Type': 'application/x-www-form-urlencoded',\n",
    "               'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',\n",
    "               'Referer': referer}\n",
    "\n",
    "    if verbose:\n",
    "        print(referer)\n",
    "    r1 = requests.get(referer, allow_redirects=True)\n",
    "    assert r1.status_code == 200, 'Make sure the website www.histdata.com is up.'\n",
    "\n",
    "    soup = BeautifulSoup(r1.content, 'html.parser')\n",
    "    try:\n",
    "        token = soup.find('input', {'id': 'tk'}).attrs['value']\n",
    "        assert len(token) > 0\n",
    "    except:\n",
    "        raise AssertionError('There is no token. Please make sure your year/month/pair is correct.'\n",
    "                             'Example is year=2016, month=7, pair=eurgbp')\n",
    "\n",
    "    data = {'tk': token,\n",
    "            'date': str(year),\n",
    "            'datemonth': '{}{}'.format(year, str(month).zfill(2)) if month is not None else str(year),\n",
    "            'platform': platform,\n",
    "            'timeframe': time_frame,\n",
    "            'fxpair': pair.upper()}\n",
    "    r = requests.post(url='https://www.histdata.com/get.php',\n",
    "                      data=data,\n",
    "                      headers=headers)\n",
    "\n",
    "    assert len(r.content) > 0, 'No data could be found here.'\n",
    "    if verbose:\n",
    "        print(data)\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "    if month is None:\n",
    "        output_filename = 'DAT_{}_{}_{}_{}.zip'.format(platform, pair.upper(), time_frame, str(year))\n",
    "    else:\n",
    "        output_filename = 'DAT_{}_{}_{}_{}.zip'.format(platform, pair.upper(), time_frame,\n",
    "                                                       '{}{}'.format(year, str(month).zfill(2)))\n",
    "    output_filename = os.path.join(output_directory, output_filename)\n",
    "    with open(output_filename, 'wb') as f:\n",
    "        for chunk in r.iter_content(chunk_size=1024):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "    if verbose:\n",
    "        print('Wrote to {}'.format(output_filename))\n",
    "    return output_filename\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "   \n",
    "    # print(download_hist_data(year='2019', month=None, platform=Platform.META_TRADER, time_frame=TimeFrame.ONE_MINUTE))\n",
    "    # print(download_hist_data(year='2018', month=None, platform=Platform.META_STOCK, time_frame=TimeFrame.ONE_MINUTE))\n",
    "    pass\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile as zf\n",
    "import os\n",
    "\n",
    "pairs = [\"USDJPY\", \"EURUSD\", \"GBPUSD\", \"USDCHF\", \"USDCAD\", \"NZDUSD\", \"XAUUSD\"]\n",
    "years = [2000, 2000, 2000, 2000, 2000,2005, 2009]\n",
    "pairs = ['USDJPY']\n",
    "years = [2000]\n",
    "last = 7\n",
    "#last_year = int(datetime.now().year)\n",
    "for pair,year in zip(pairs,years):\n",
    "  for y in range(year,2022):\n",
    "    download_hist_data(year=str(y), pair=pair.lower(),month=None, platform=Platform.META_TRADER, time_frame=TimeFrame.ONE_MINUTE, verbose=False)\n",
    "\n",
    "  for m in range(1,last):\n",
    "    download_hist_data(year='2022', pair=pair.lower(),month=str(m), platform=Platform.META_TRADER, time_frame=TimeFrame.ONE_MINUTE, verbose=False)\n",
    "\n",
    "  \n",
    "  name = \"DAT_MT_\"+pair+\"_M1_20\"\n",
    "  for i in range(year%100,22):\n",
    "    strr = name\n",
    "    if i<10:\n",
    "      strr+='0'+str(i)+'.zip'\n",
    "    else :\n",
    "      strr+=str(i)+'.zip'\n",
    "    #!unzip strr\n",
    "    files = zf.ZipFile(strr,'r')\n",
    "    files.extractall()\n",
    "    files.close()\n",
    "    os.remove(strr)\n",
    "    strr = strr[:-4]\n",
    "    strr += '.txt'\n",
    "    os.remove(strr)\n",
    "\n",
    "\n",
    "  name = \"DAT_MT_\"+pair+\"_M1_20220\"\n",
    "  for i in range(1,last):\n",
    "    strr = name\n",
    "    strr+=str(i)+'.zip'\n",
    "    #!unzip strr\n",
    "    files = zf.ZipFile(strr,'r')\n",
    "    files.extractall()\n",
    "    files.close()\n",
    "    os.remove(strr)\n",
    "    strr = strr[:-4]\n",
    "    strr += '.txt'\n",
    "    os.remove(strr)\n",
    "\n",
    "  \n",
    "  data = pd.read_csv('DAT_MT_'+pair+'_M1_'+str(year)+'.csv', names=[\"date\", \"open\", \"high\", \"low\", \"close\", \"volume\"])\n",
    "  os.remove('DAT_MT_'+pair+'_M1_'+str(year)+'.csv')\n",
    "  name = \"DAT_MT_\"+pair+\"_M1_20\"\n",
    "  for i in range(year%100+1,22):\n",
    "    strr = name\n",
    "    if i<10:\n",
    "      strr+='0'+str(i)+'.csv'\n",
    "    else :\n",
    "      strr+=str(i)+'.csv'\n",
    "    df = pd.read_csv(strr, names=[\"date\", \"open\", \"high\", \"low\", \"close\", \"volume\"])\n",
    "    data = pd.concat([data,df])\n",
    "    os.remove(strr)\n",
    "\n",
    "  name = \"DAT_MT_\"+pair+\"_M1_20220\"\n",
    "  for i in range(1,last):\n",
    "    strr = name\n",
    "\n",
    "    strr+=str(i)+'.csv'\n",
    "    df = pd.read_csv(strr, names=[\"date\", \"open\", \"high\", \"low\", \"close\", \"volume\"])\n",
    "    data = pd.concat([data,df])\n",
    "    os.remove(strr)\n",
    "\n",
    "\n",
    "  data.drop('volume', axis=1, inplace=True)\n",
    "  data.reset_index(inplace=True) \n",
    "  print(pair+\" shape : \",data.shape)\n",
    "\n",
    "  data.to_csv(pair+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f808aad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-01T18:51:21.950663Z",
     "iopub.status.busy": "2022-07-01T18:51:21.950263Z",
     "iopub.status.idle": "2022-07-01T18:51:21.955668Z",
     "shell.execute_reply": "2022-07-01T18:51:21.954567Z"
    },
    "papermill": {
     "duration": 0.011693,
     "end_time": "2022-07-01T18:51:21.958005",
     "exception": false,
     "start_time": "2022-07-01T18:51:21.946312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pairs = [\"USDJPY\", \"EURUSD\", \"GBPUSD\", \"USDCHF\", \"USDCAD\", \"NZDUSD\", \"XAUUSD\"]\n",
    "# timee = ['1','5', '10', '30', '1440', '43200']\n",
    "\n",
    "# for pair in pairs:\n",
    "#     for mi in timee:\n",
    "#         data = pd.read_csv(pair+'.csv')\n",
    "#         data['index'] +=' '\n",
    "#         data['index'] += data['date'] \n",
    "#         data[\"date\"] = data[\"index\"].apply(lambda x: x.replace('.','-'))\n",
    "#         data['date']+=':00'\n",
    "#         data.drop('index',axis=1, inplace=True)\n",
    "#         data.set_index('date', inplace=True)\n",
    "#         data.index = pd.DatetimeIndex(data.index)\n",
    "#         data = data.resample(mi+'Min').agg({'open': 'first', 'high': 'max', 'low': 'min', 'close': 'last'})\n",
    "#         is_NaN = data.isnull()\n",
    "#         row_has_NaN = is_NaN.any(axis=1)\n",
    "#         rows_with_NaN = data[row_has_NaN]\n",
    "#         data.drop(rows_with_NaN.index,inplace=True)\n",
    "#         data.reset_index(inplace=True)\n",
    "#         data.to_csv(pair+' '+mi+'.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2068e72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-01T18:51:21.965191Z",
     "iopub.status.busy": "2022-07-01T18:51:21.964770Z",
     "iopub.status.idle": "2022-07-01T18:51:21.969361Z",
     "shell.execute_reply": "2022-07-01T18:51:21.968237Z"
    },
    "papermill": {
     "duration": 0.010825,
     "end_time": "2022-07-01T18:51:21.971524",
     "exception": false,
     "start_time": "2022-07-01T18:51:21.960699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# for pair in pairs:\n",
    "#     os.remove(pair+'.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 137.950108,
   "end_time": "2022-07-01T18:51:22.696377",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-07-01T18:49:04.746269",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
